{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KQAzjqi2jdQ"
      },
      "outputs": [],
      "source": [
        "!pip install numpy matplotlib scikit-learn opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "qcvNkcO42491"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/mail imag.png'\n",
        "img = cv2.imread(img_path)\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img_resized = cv2.resize(img_gray, (64, 64))\n",
        "img_normalized = img_resized / 255.0"
      ],
      "metadata": {
        "id": "JrA4-bzB4XIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_expanded = np.expand_dims(img_normalized, axis=-1)\n",
        "img_batch = np.expand_dims(img_expanded, axis=0)"
      ],
      "metadata": {
        "id": "wQCzJnBd9tuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rotation_range=30, zoom_range=0.2, horizontal_flip=True)\n",
        "\n",
        "augmented_images = []\n",
        "for i, batch in enumerate(datagen.flow(img_batch, batch_size=1)):\n",
        "    augmented_images.append(batch[0])\n",
        "    if i >= 19:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "ctzoNFw8-kBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(augmented_images)\n",
        "y = np.array([0] * 20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Gue8PR9T-ts2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(128, activation='relu'))\n",
        "cnn_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "h6ALl2rB-15F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(X_train, y_train, epochs=4, batch_size=4, validation_split=0.2)\n",
        "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test, y_test)\n",
        "print(f'Accuracy of CNN on augmented images: {cnn_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "UYFi0FiM-53R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the dataset\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "X = lfw_people.images\n",
        "y = lfw_people.target\n",
        "\n",
        "# Preprocess the data\n",
        "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)  # Add channel dimension for grayscale\n",
        "X = X / 255.0  # Normalize pixel values\n",
        "\n",
        "# Convert labels to categorical\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(y_train.shape[1], activation='softmax')  # Output layer for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {score[1]*100:.2f}%\")\n",
        "\n",
        "# Function to load and preprocess a custom image for testing\n",
        "def preprocess_image(image_path, target_size):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
        "    img_resized = cv2.resize(img, target_size)  # Resize to match the CNN input\n",
        "    img_resized_reshaped = img_resized.reshape(1, target_size[0], target_size[1], 1)  # Add batch and channel dimensions\n",
        "    img_resized_reshaped = img_resized_reshaped / 255.0  # Normalize pixel values\n",
        "    return img, img_resized_reshaped  # Return original and processed images\n",
        "\n",
        "# Path to your custom test image\n",
        "image_path = '/content/mail imag.png'  # Update this with your image path\n",
        "\n",
        "# Preprocess the custom image\n",
        "original_image, input_image = preprocess_image(image_path, (X_train.shape[1], X_train.shape[2]))\n",
        "\n",
        "# Predict the class of the input image\n",
        "prediction = model.predict(input_image)\n",
        "\n",
        "# Get the class label\n",
        "predicted_class = np.argmax(prediction)\n",
        "predicted_label = lfw_people.target_names[predicted_class]\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"Predicted class: {predicted_label}\")\n",
        "\n",
        "# Display the input image along with the predicted class\n",
        "plt.imshow(original_image, cmap='gray')  # Display image in grayscale\n",
        "plt.title(f\"Predicted class: {predicted_label}\")  # Set the title to show the predicted class\n",
        "plt.axis('off')  # Hide the axis for better view\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZsrwlfSGFG72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from google.colab import files\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Upload the image\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract the filename from the uploaded files\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Function to extract features using VGG16 CNN\n",
        "def extract_features_with_cnn(image_path):\n",
        "    # Load the VGG16 model pre-trained on ImageNet, excluding the top layers (we're not interested in classification)\n",
        "    base_model = VGG16(weights='imagenet', include_top=False)\n",
        "    model = Model(inputs=base_model.inputs, outputs=base_model.get_layer('block5_pool').output)\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    img = cv.imread(image_path)\n",
        "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "    img_resized = cv.resize(img_rgb, (224, 224))  # Resize image to 224x224 as required by VGG16\n",
        "    img_array = np.expand_dims(img_resized, axis=0)  # Expand dimensions to fit batch format\n",
        "    img_preprocessed = preprocess_input(img_array)  # Preprocess image\n",
        "\n",
        "    # Extract features using the VGG16 model\n",
        "    features = model.predict(img_preprocessed)\n",
        "\n",
        "    # Reshape features to 2D (samples, features)\n",
        "    features_reshaped = features.reshape(-1, features.shape[-1])\n",
        "\n",
        "    return features_reshaped\n",
        "\n",
        "# Function to perform K-means clustering and compare accuracy with and without PCA\n",
        "def kmeans_with_and_without_pca(image_path, cluster_n):\n",
        "    # Step 1: Feature extraction using CNN (VGG16 in this case)\n",
        "    features = extract_features_with_cnn(image_path)\n",
        "\n",
        "    # ---------- Without PCA ----------\n",
        "    # Step 2: Perform K-means clustering on raw CNN features (without PCA)\n",
        "    kmeans_no_pca = KMeans(n_clusters=cluster_n)\n",
        "    labels_no_pca = kmeans_no_pca.fit_predict(features)\n",
        "\n",
        "    # ---------- With PCA ----------\n",
        "    # Step 4: Apply PCA to reduce dimensionality for clustering\n",
        "    pca = PCA(n_components=2)\n",
        "    features_pca = pca.fit_transform(features)\n",
        "\n",
        "    # Step 5: Perform K-means clustering on PCA-transformed features\n",
        "    kmeans_pca = KMeans(n_clusters=cluster_n)\n",
        "    labels_pca = kmeans_pca.fit_predict(features_pca)\n",
        "\n",
        "    # Step 6: Evaluate clustering with silhouette score (with PCA)\n",
        "    silhouette_pca = silhouette_score(features_pca, labels_pca)\n",
        "    print(f\"Accuracy Score with PCA: {silhouette_pca:.4f}\")\n",
        "\n",
        "    # Step 7: Create a scatter plot for PCA\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    scatter = plt.scatter(features_pca[:, 0], features_pca[:, 1], c=labels_pca, cmap='tab10', s=20)\n",
        "    plt.colorbar(scatter, ticks=range(cluster_n), label='Cluster')\n",
        "    plt.title('PCA of CNN-extracted Features (with K-means Clustering)')\n",
        "    plt.xlabel('Principal Component 1')\n",
        "    plt.ylabel('Principal Component 2')\n",
        "    plt.show()\n",
        "\n",
        "# Number of clusters\n",
        "cluster_n = 7\n",
        "\n",
        "# Perform K-means clustering with and without PCA and compare silhouette scores\n",
        "kmeans_with_and_without_pca(image_path, cluster_n)"
      ],
      "metadata": {
        "id": "autqeLtQHGIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AyWCf609J2Kk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}